卷积功能屏蔽的联合对象和物体分割
作者：
译者：

摘要：
语法分割已经看到了相当大的进步，因为卷积神经网络的强大学习特征。最近语法分割的前沿研究是通过从模糊图像区域提取卷积神经网络特征，探索图形信息。这种方法提出在图像方面人工的局限，并且可能影响提取的特征质量。而且在未处理过的图像领域操作，需要在一幅图像上计算上千个神经网络，这个非常耗时。
在这篇文章中，我们提出通过模糊卷积方法探索图形信息。该提案在卷积特点图上被当作面具（遮罩层）/*选一*/。分片的卷积神经网络特点被从这些图中直接遮盖掉，并且用于识别分类。我们进一步提出一个联合方法在相同的框架中处理对象和事物。最先进的计算结果用令人信服的计算速度在PASCAL VOC基准和PASCAL-CONTEXT上演示。
1、介绍
语法分割[14, 19, 24, 2]目的是把每一个图形像素标记为语法类别。最近在卷积神经网络上的重大突破已经大大提高了基于R-CNN方法的语法分割的技术水平。语法分割的R_CNN方法提取CNN特征的两种类型，一种是，从建议包围盒提取的区域特征；另一种是从被分割遮盖的原生图形中提取分割特点。这些特点的一系列相关事物被用于训练分类。这种方法在这个长期挑战性的项目中已经演示了一个可靠的结果。然而基于原生图像的R_CNN方法有两个小问题。第一在图片内容上的遮罩可能导致“人工边界”。这些边界在提前训练的网络中的样本上并未出现。这个问题可能降低所提取的分割特点的质量。第二类似于R_CNN方法对物体的识别，这些方法需要把网络应用到成千上万的有（没有）遮罩的原生图片区域。这是非常耗时的甚至在高端GPU上也是如此。
第二个问题同样存在于基于对象识别的R_CNN中。幸运的是，它在很大程度上可以通过最近一种称为SPP_Net的技术解决。这种技术只在整幅图像上计算一次卷积特点图并且应用一种空间金字塔池的技术形成对于分类的裁剪功能。通过这些裁剪特征的检测结果表明有竞争力的检测精度并且速度可以提高50倍以上。因此，在这篇文章中我们提出一个问题：对于语法分割，我们可以只用卷积特点图吗？
这个工作的第一部分对这个问题做了肯定的回答。我们设计了一种卷积特点屏蔽法，直接从特点图而不是原生图像中直接提取分割特征。用区域建议法给出的分割，我们预测他们到最后卷积特征映射域。投影段对屏蔽卷积功能表现为二进制函数。被屏蔽的特征然后被送到识别的完全连接层。因为卷积特征是从未屏蔽的图像上计算得到的所以其质量不受影响。因而这种方法在卷积特征映射上是有效的，且仅需计算一次。前面提到的两个语义分割问题就这样解决了。图1比较了基于原始图像的流水线和我们基于特点映射的流水线。这篇文章的第二部分为了链接对象和事物进一步一般化我们的方法。和对象不同的是，事物（例如：天空，草地，水）通常被作为图像中的环境。事物大部分表现为颜色或纹理，并且有着不易确定的外形。因此用一个简单的矩形框或简单分割来描述事物是不合适的。基于我们的屏蔽卷积特征，我们提出了一个训练过程——把一个事物作为一个多分割特征的紧密组合体。这使我们能够解决在同一框架内的对象和事物。
/*******************************/
             图1
/*******************************/
基于以上方法，我们在PASCAL_VOC2012基准上展示了高技术的成果。我们的方法可以在少于1秒钟的时间内处理一幅图像，这比基于SDS的R_CNN方法快乐150多倍。而且我们的方法也是第一个基于深度学习的方法，曾被应用到新标记PASCAL_CONTEXT标杆，在对象和事物分割两方面我们的结果都大大由于以前的最优技术。
2、卷积特征屏蔽法
2.1 卷积特征屏蔽层
卷积神经网络作为一个一般特征提取器已经逐渐在计算机视觉领域显示出它的强大之处。在Krizhevsky——et——al的工作中，他们建议在全连接层的特征可以被用来作为整幅图像的特征，例如：图像检索。在【6，25】这些全面的功能是作为通过迁移学习通用的功能在其他数据集全图像分类任务。在破目标检测的R_CNN的文章中。CNN特征也被当作整体特征使用，但要从原生图像修剪后的子图像中提取。在基于CNN的语法分割的文章中，R_CNN方法一般化为遮罩原生图像区域。对所有的方法来说，整个网络被训练为完整特征提取器，无论是在整个图像或子图像中。在SPP_Net最近的工作中，它表明，该卷积特征图可以用作局部特征。在一个整幅图像的卷积特征图中，局部矩形区域语义信息（通过激活的优势）和空间信息（通过位置）编码。这些局部区域的特征可以直接汇集起来做识别。
SPP在【11】实际上扮演两个角色：1）用一个矩形区域屏蔽特征图，之外的激活部分被移除。2）产生从该任意大小的区域的定长特征。所以，如果用一个矩形屏蔽可以是有效的，我们要是用一个良好的不规则分割图形屏蔽特征图会如何呢？
卷积特征屏蔽层就这样产生了。我们首先获得原始图像上的候选段（如超象素）。很多局部建议法是基于超像素的。每一个建议框通过分组几个超像素给出。我们称这样的一个组为分割提议。因此我们可以同时获得候选段和他们的提议框（在文中称为区域）而不用额外的努力。这些段都在原始图像的二进制屏蔽。
接下来我们预计这些二进制口罩的域最后卷积特征图。因为在卷积特征图中每个激活区域是由一个在图像区域的感受视野贡献的。我们首先预测每一个激活区到图像区域作为它的接受视野的中心（在【11】中的细节之后）。在图像上的二进制掩模的每个像素被分配到其最接近的感受野中心。之后这些像素被预测回到卷积特征图域中，基于中心和它的激活位置。在特征图中，每个位置将要从二进制屏蔽中收集多个被预测的像素。然后对这些二进制值求取平均值和阈值（0.5）化操作。这给了我们一个在特征图中的屏蔽层（图2）。这个面具被用到卷积特征图中。实际上我们只需要在特征图的每一个通道上乘以这个二进制屏蔽。在我们的方法中称最终特征为分割特征。
2.2 网络设计
在【10】中已经展示仅有分割特征是不够的。这些分割特征应该和被用一种像R_CNN方法一般化的原始特征（来自边界框）一块用。基于我们的CFM层，有两种方法可以这样做。
设计A：在最后的卷积层：就像在图3（左部）展示的一样，在最后的卷积层之后我们一般化了两种特征源。一种是由SPP层产生的区域特征，就像在【11】中一样。另一个是由接下来的方法产生的分割特征。CFM层被用到整幅图像的卷积特征图中。这给了我们一个任意大小（就边界框而言）的段特征。然后我们用另一个SPP层在这个特征上产生一个固定长度的输出。两类汇集特征被送到两个分开的FC层中。最后的FC层的特征被级联来训练分类器，就像【10】中的分类器。在本设计中，我们在FC层的训练和测试中有两种途径。
设计B：空间金字塔汇集层。我们首先采用SPP层来汇集特征。我们用一个{6 × 6, 3 × 3, 2 × 2, 1 × 1}的4层金字塔像在【11】中的一样。6X6层实际上是一个很小的6X6的特征图，它仍有足够的空间信息。我们把CFM层用在这个极小的特征图中产生分割特征。这个特征则与其它三个层拼接后送到FC层，想在图3右部展示的一样。
在这个设计中，我们保留一种fc层的通路来减少计算开销和过拟合的风险。
2.3 训练和推理
基于这两个设计和CFM层，顺着在【8，11，10】中的普通练习，训练和推理阶段可以很容易进行。在这两个阶段中，我们用区域提案算法产生大约2000个区域提案和相关的段。输入图像调整为多尺度（较短的边 s 《 {480, 576, 688, 864, 1200}），并且
卷积特征图从全图像中提取然后固定（不会进一步调整）。
训练。我们首先用SPP方法为物体检测微调一个网络。然后我们用设计A或B中的体系架构更换微调的网络，然后进一步为分割微调网络。在第二个微调步骤中，段提案覆盖地面实况前景的【0.5-1】是效果较好的，【0.1-0.3】效果是相当差的。该覆盖由基于两个段区域（而不是他们的边界框）的IoU得分评定。在微调后，我们训练一个在网络输出上的现行SVM分类器，为每一个类别。在SVM训练中，仅有地面实况段被用作良好样例。
推理。每一个区域提案被分配一个合适的尺度如在【11】中的一样。每一个区域的特征和他的相关段被提取出来如在设计A或B。SVM分类器被用作给每一个区域打分。
给出所有的评分区域提案，我们通过在SDS通过的方案获取像素等级分类标签。这个通过的方案顺序选择最高分的区域提案，执行区域细化，抑制重叠的建议，和把像素标签粘贴到标签的结果上。区域细化提高了PASCAL VOC 2012大约1%的精度为SDS和我们的方法。
2.4 在对象分割上的结果
我们在PASCAL VOC 2012语法分割基准上评估我们的方法，那有20个对象类别。我们遵从“comp6”评估协议，那也被用在【4，8，11】。PASCAL VOC 2012的系列训练和来自【9】附加的分割注释被用来训练和在【4，8，10】中评估。研究了两个场景：语法分割和同时检测和分割。
场景 I：语法分割
在语法分割的试验中，类标签被分配给图像中的所有像素，并且精确度有区域IoU得分评估。
我们首先研究用“ZF SPPnet”模型作为我们的特征提取器。这个模型是基于Zeiler 和 Fergus的快速模型但是带有SPP层。它有五个卷积层和三个fc层。这个模型适合【11】的代码一起发布的。我们注意到，在R-CNN[8]和SDS[10]的结果用“AlexNet”[13]来代替。要了解预先训练模式的影响，我们以PASCAL
VOC 2012系列数字的形式报告它们的物体探测mAP：SPP-Net (ZF) 是 51.3%, R-CNN (AlexNet) 是
51.0%, 和 SDS (AlexNet) 是 51.9%。这意味着这两个预训练的模型是可作为一般特征提取器的。所以CFM以下的收益并不只是由于
预先训练的模型。展示出CFM层的作用，我们展现出一个没有CFM的基准线——在我们的设计B中，我们移除了CFM层但仍用相同的整个流水线。我们称这种基线为我们方法的“无CFM”的版本。实际上，这个基准线降低到原始SPP-net使用，除了正/负样本的定义是分割。表1无CFM的结果和CFM的两种设计比较。我们发现，CFM具有明显的在非CFM基线优点。这是预料之中的，因为无CFM基线也没有任何基于细分特点。此外，我们发现，设计A和B只是表现相当，而A需要计算FC层的两种途径。因此，本文的其余部分，我们采用B型设计的ZF SPPnet。
在表2中，我们使用不同的区域建议算法评估我们的方法。我们采取两种方案算法：选择性搜索（SS），和多尺度组合分组（(MCG)）。遵从【10】中的协议，“快”模式用于SS，“准确”模式用于MCG。表2显示，我们的方法实现在MCG建议更高的精度。这表明我们的特征掩蔽方法能够通过更准确的分割建议生成信息。
表1，表2，表3，表4
在表2中，我们还评估预训练网络的影响。我们比较ZF——SPPnet与公开VGG——16模型【20】在图像分类中的最新进展表明，非常深的网络[20]可以显著提高分类准确率。该VGG-16模型有13卷积和3层FC。因为该模型具没有SPP层，我们考虑它最后的聚集层（7×7），是一个{7×7}单级金字塔特殊SPP层。在这种情况下，我们的设计B不适用，因为没有粗糙层。因此我们用设计A代替。表2表明，在使用VGGnet我们的结果时大幅改善。这表明，我们的方法，从比较有代表性的特征通过更深层次的模型学习而获益。
在表3我们评估图像尺寸的影响。除了使用5尺度，我们只是从单级图像提取特征，它的短边为S=576。表3表明，我们的单尺度变体具有可忽略的降解。但单规模变体具有更快的计算速度如表4。
接下来，我们与国家的最先进成果的比较在PASCAL——VOC2012测试表5中设置。在这里，SDS【10】在这方面以前最先进的方法，并且O2P[4]是一个领先的非基于CNN的方法。我们方法用ZF——SPPnet和MCG取得了55.4分。这比在【10】中报道的SDS结果提高了3.8%，它用的是AlexNet和MCG。这表明，我们的CFM方法在没有掩盖原始像素图像的条件下可以产生有效的特征。用VGG——net，我们的方法对试验组的得分为61.8。
除了高精确性，我们的方法比SDS快得多。用SDS和我们的方法在特征提取步骤中运行时间如表4所示。这两种方法都是基于Caffe库并在Nvidia的GTX GPU泰坦上运行。时间是取从PASCAL——VOC随机的100张图像的平均值。用尺度5，我们用ZF——SPPnet的方法比SDS快了47倍以上；用尺度1，我们用ZF——SPPnet的方法比SDS快150倍以上而且更加精确。速度改善是因为我们的方法只需要计算一次特征图。表4表明我们的方法在用VGGnet时仍是可行的。
与我们的工作同步，一种全卷积网络（FCN）方法被提出用于语法分割。它有一个分数（在测试集上62.2）与我们的方法相当，且速度快因为它也只需在整幅图像上进行一次卷积。但是FCN不能产生一个实例明智的结果，这是10中的另一个评价指标。我们的方法也可以适用于这种情况下，如下评估。
场景II：同时检测和分割
在同时检测和分割的评估协议中，所有的对象实例和它们的分割遮罩都被标记。和语法分割相对比，这个场景要求除了标记逐像素的语法分类还要进一步识别不同的对象实例。精度是由在【10】中定义的APr得分确定的。
接下来我们公布在VOC2012确认集的APr平均值，作为地面真标签测试集不可用。如在表6中展示的，当用ZF——SPPnet和MCG时我们的方法的APr平均值为53.2。这要比在【10】中公布的SDS结果要好。用VGGnet我们的APr平均值为60.7，那是这方面的国际最先进结果。注意到，FCN方法在评价公知APr平均值是不适用的。因为它不能产生对象实例。
表5，表6
3. 链接对象和事物分割
在自然图像中的语法分类可以被大致分为对象和事物。对象有确定的外形且每一个实例都是可数的，而事物有确定的颜色或纹理且表现为任意形状，如，草地，天空和水。因此不同于对象，事物区域是不恰当的被表示为矩形区域或边界框。当我们的方法可以产生段特征，每一个段仍然和一个边界框相关联因为他的产生方法。当区域或段提议被提出后，事物可以被一个单一段完全覆盖是很稀少的。即使事物被单个矩形框区域覆盖，几乎可以确定在这个区域的很多像素并不属于这个事物。因此事物分割有着不同于对象分割的问题。
接下来我们将展示我们的框架的一个推广，以减少在事物中包含的问题。我们可以通过一个单一的解决方案，同时处理对象和东西。尤其，卷积特征图仅需要被计算一次。因此如果算法被要求进一步处理事物会有一个较小的额外的开销。
我们的推广是训练期间修改样品的底层概率分布。不同于同等对待样本，我们的训练将要有偏差的对待提议并尽可能紧凑（如下讨论的）的覆盖事物。一个段追求过程被提出来发现紧凑提案。
3.1 由段组合代表的事物
我们把事物作为一个多段建议的组合体。我们期望一个段提议可以尽可能多的覆盖一个事物的局部。与此同时，我们希望这些段提议能够紧凑一些，段越少越好。
我们首先为事物分割定义一个段建议的候选集。我们定义一个纯分数作为一个段建议和段的边界框内事物部分的IoU比值。其中在单个图像所有的段建议，那些具有高纯度的分数（》0.6）和事物组成潜在的组合候选集。
要从此候选集产生一个紧凑的组合，我们采用类似匹配追踪程序
[23，17]。我们依次从候选集中挑选段无需更换。每一步最大的段建议被选中。被选中的段然后抑制在候选集（他们以后也不会被选到）中高度重叠的建议。在本文中，抑制重叠阈值设置为IOU= 0.2。重复该过程，直到剩余的段都具有比阈值更小的区域，这是分段区中的（图像集的）初始候选集的平均。我们称这个程序段的追求。
图4（b）展示了一个例子如果段的提议是随机从候选集合采样。我们看到那有很多小的段。定义这些小段是不利的，识别力差的段要么是积极的要么是消极的样本（例如：由IoU评估）-如果他们是积极的，他们只是事物的一小部分；如果他们是消极的，他们共享像事物的大部分一样的纹理和颜色。因此我们更愿意在训练中忽视这些样本，所以分类器不会偏见对待这些小样本的任一方。图4（c）展示了由段追求选出的段建议。我们看到他们可以仅通过几个很大的段覆盖事物（这里是草地）。我们期待一个更多依赖这样一个提议组合的解决方法。
然而，上述过程是确定性的，并且可以给出每一幅图像的小样本集。例如，在图4（c）它仅提供了5个段建议。在微调程序中，我们需要用来训练的大量随机样本。因此我们在上述段追求程序中注入随机性。在每一步中，我们从候选集中随机抽取段建议，而不是用最大的。采摘概率正比于一个区段的区域大小（因此一个大的仍是更有可能的）。这可以以随机的方式给我们另一个紧凑的组合。图4（d）展示了一个在几次试验中产生的段建议的样本。
